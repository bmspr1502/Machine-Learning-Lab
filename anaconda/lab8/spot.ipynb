{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def tanh(z):\n",
    "\treturn (np.exp(z) - np.exp(-z)) / (np.exp(z) + np.exp(-z))\n",
    "\n",
    "class mlp:\n",
    "    \"\"\"A Multi-Layer Perceptron\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, inputs, targets, nhidden, beta=1, momentum=0.9, outtype=\"logistic\"\n",
    "    ):\n",
    "        \"\"\"Constructor\"\"\"\n",
    "        self.nin = np.shape(inputs)[1]\n",
    "        self.nout = np.shape(targets)[1]\n",
    "        self.ndata = np.shape(inputs)[0]\n",
    "        self.nhidden = nhidden\n",
    "\n",
    "        self.beta = beta\n",
    "        self.momentum = momentum\n",
    "        self.outtype = outtype\n",
    "\n",
    "        # Initialise network\n",
    "        self.weights1 = (\n",
    "            (np.random.rand(self.nin + 1, self.nhidden) - 0.5) * 2 / np.sqrt(self.nin)\n",
    "        )\n",
    "        self.weights2 = (\n",
    "            (np.random.rand(self.nhidden + 1, self.nout) - 0.5)\n",
    "            * 2\n",
    "            / np.sqrt(self.nhidden)\n",
    "        )\n",
    "\n",
    "    def earlystopping(\n",
    "        self, inputs, targets, valid, validtargets, eta, niterations=10000\n",
    "    ):\n",
    "\n",
    "        valid = np.concatenate((valid, -np.ones((np.shape(valid)[0], 1))), axis=1)\n",
    "\n",
    "        old_val_error1 = 100002\n",
    "        old_val_error2 = 100001\n",
    "        new_val_error = 100000\n",
    "\n",
    "        print(\"No. of neurons in hidden layers = \", self.nhidden)\n",
    "        while ((old_val_error1 - new_val_error) > 0.001) or (\n",
    "            (old_val_error2 - old_val_error1) > 0.001\n",
    "        ):\n",
    "            self.mlptrain(inputs, targets, eta, niterations)\n",
    "            old_val_error2 = old_val_error1\n",
    "            old_val_error1 = new_val_error\n",
    "            validout = self.mlpfwd(valid)\n",
    "            new_val_error = 0.5 * np.sum((validtargets - validout) ** 2)\n",
    "\n",
    "        print(\"Stopped, error = \", new_val_error)\n",
    "        return new_val_error\n",
    "\n",
    "    def mlptrain(self, inputs, targets, eta, niterations):\n",
    "        \"\"\"Train the neural network\"\"\"\n",
    "        # Add the inputs that match the bias node\n",
    "        inputs = np.concatenate((inputs, -np.ones((self.ndata, 1))), axis=1)\n",
    "        change = range(self.ndata)\n",
    "\n",
    "        updatew1 = np.zeros((np.shape(self.weights1)))\n",
    "        updatew2 = np.zeros((np.shape(self.weights2)))\n",
    "\n",
    "        for n in range(niterations):\n",
    "\n",
    "            self.outputs = self.mlpfwd(inputs)\n",
    "\n",
    "            error = 0.5 * np.sum((self.outputs - targets) ** 2)\n",
    "\n",
    "            # Different types of output neurons and their activation functions\n",
    "            if self.outtype == \"linear\":\n",
    "                deltao = (self.outputs - targets) / self.ndata\n",
    "            elif self.outtype == \"logistic\":\n",
    "                deltao = (\n",
    "                    self.beta\n",
    "                    * (self.outputs - targets)\n",
    "                    * self.outputs\n",
    "                    * (1.0 - self.outputs)\n",
    "                )\n",
    "            elif self.outtype == \"softmax\":\n",
    "                deltao = (\n",
    "                    (self.outputs - targets)\n",
    "                    * (self.outputs * (-self.outputs) + self.outputs)\n",
    "                    / self.ndata\n",
    "                )\n",
    "            elif self.outtype == \"tanh\":\n",
    "                deltao = (\n",
    "                    (self.outputs - targets)\n",
    "                    * (1.0 - np.power(self.outputs, 2))\n",
    "                )\n",
    "            else:\n",
    "                print(\"error\")\n",
    "\n",
    "            # hidden network delta\n",
    "            deltah = (\n",
    "                self.hidden\n",
    "                * self.beta\n",
    "                * (1.0 - self.hidden)\n",
    "                * (np.dot(deltao, np.transpose(self.weights2)))\n",
    "            )\n",
    "\n",
    "            updatew1 = (\n",
    "                eta * (np.dot(np.transpose(inputs), deltah[:, :-1]))\n",
    "                + self.momentum * updatew1\n",
    "            )\n",
    "            updatew2 = (\n",
    "                eta * (np.dot(np.transpose(self.hidden), deltao))\n",
    "                + self.momentum * updatew2\n",
    "            )\n",
    "            self.weights1 -= updatew1\n",
    "            self.weights2 -= updatew2\n",
    "\n",
    "            return error\n",
    "\n",
    "    def mlpfwd(self, inputs):\n",
    "        \"\"\"Run the network forward\"\"\"\n",
    "\n",
    "        self.hidden = np.dot(inputs, self.weights1)\n",
    "        self.hidden = 1.0 / (1.0 + np.exp(-self.beta * self.hidden))\n",
    "        self.hidden = np.concatenate(\n",
    "            (self.hidden, -np.ones((np.shape(inputs)[0], 1))), axis=1\n",
    "        )\n",
    "\n",
    "        outputs = np.dot(self.hidden, self.weights2)\n",
    "\n",
    "        # Different types of output neurons\n",
    "        if self.outtype == \"linear\":\n",
    "            return outputs\n",
    "        elif self.outtype == \"logistic\":\n",
    "            return 1.0 / (1.0 + np.exp(-self.beta * outputs))\n",
    "        elif self.outtype == \"softmax\":\n",
    "            normalisers = np.sum(np.exp(outputs), axis=1) * np.ones(\n",
    "                (1, np.shape(outputs)[0])\n",
    "            )\n",
    "            return np.transpose(np.transpose(np.exp(outputs)) / normalisers)\n",
    "        elif self.outtype == \"tanh\":\n",
    "            return tanh(outputs)\n",
    "        else:\n",
    "            print(\"error\")\n",
    "\n",
    "\n",
    "    def confmat(self, inputs, targets):\n",
    "        \"\"\"Confusion matrix\"\"\"\n",
    "\n",
    "        # Add the inputs that match the bias node\n",
    "        inputs = np.concatenate((inputs, -np.ones((np.shape(inputs)[0], 1))), axis=1)\n",
    "        outputs = self.mlpfwd(inputs)\n",
    "\n",
    "        nclasses = np.shape(targets)[1]\n",
    "\n",
    "        if nclasses == 1:\n",
    "            nclasses = 2\n",
    "            outputs = np.where(outputs > 0.5, 1, 0)\n",
    "        else:\n",
    "            # 1-of-N encoding\n",
    "            outputs = np.argmax(outputs, 1)\n",
    "            targets = np.argmax(targets, 1)\n",
    "\n",
    "        cm = np.zeros((nclasses, nclasses))\n",
    "        for i in range(nclasses):\n",
    "            for j in range(nclasses):\n",
    "                cm[i, j] = np.sum(\n",
    "                    np.where(outputs == i, 1, 0) * np.where(targets == j, 1, 0)\n",
    "                )\n",
    "        output = cm\n",
    "        print(\"Percentage Correct: \", np.trace(cm) / np.sum(cm) * 100)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "df1 = pd.read_csv('Real Estate.csv')\n",
    "\n",
    "data1 = df1.drop(['Y house price of unit area'], axis = 1)\n",
    "target1 = df1['Y house price of unit area']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "datasets = train_test_split(data1, target1,\n",
    "                            test_size=0.3)\n",
    "\n",
    "X_train, X_test, y_train, y_test = datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val = X_train.to_numpy()\n",
    "y_train_val = y_train.to_numpy().flatten()\n",
    "X_test_val = X_test.to_numpy()\n",
    "Y_test_val = y_test.to_numpy().flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(289,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t =y_train_val.flatten()\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-d2fd485b0752>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouttype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-32-30134534f79a>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, targets, nhidden, beta, momentum, outtype)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;34m\"\"\"Constructor\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnhidden\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "net = mlp(X_train_val, y_train_val, 25, outtype='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-fc0eca3559ab>:118: RuntimeWarning: overflow encountered in exp\n",
      "  self.hidden = 1.0 / (1.0 + np.exp(-self.beta * self.hidden))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "68981339.9142391"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.mlptrain(X_train_val, y_train_val, 0.001,20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.concatenate((X_test_val,-np.ones((np.shape(X_test_val)[0],1))),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-fc0eca3559ab>:118: RuntimeWarning: overflow encountered in exp\n",
      "  self.hidden = 1.0 / (1.0 + np.exp(-self.beta * self.hidden))\n"
     ]
    }
   ],
   "source": [
    "out=net.mlpfwd(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 289)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (125,289) (125,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-8917dc72643f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mY_test_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (125,289) (125,) "
     ]
    }
   ],
   "source": [
    "print (0.5*sum((out-Y_test_val)**2))\n",
    "\n",
    "print (out)\n",
    "print (out.mean(axis=0))\n",
    "print (out.var(axis=0))\n",
    "print (out.max(axis=0))\n",
    "print (out.min(axis=0))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
